<!doctype html>
<html>
<head>
<meta charset="UTF-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<meta http-equiv="X-UA-Compatible" content="ie=edge" />
<title>Markmap</title>
<style>
* {
  margin: 0;
  padding: 0;
}
html {
  font-family: ui-sans-serif, system-ui, sans-serif, 'Apple Color Emoji',
    'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji';
}
#mindmap {
  display: block;
  width: 100vw;
  height: 100vh;
}
.markmap-dark {
  background: #27272a;
  color: white;
}
</style>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/markmap-toolbar@0.18.12/dist/style.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@highlightjs/cdn-assets@11.11.1/styles/default.min.css">
</head>
<body>
<svg id="mindmap"></svg>
<script src="https://cdn.jsdelivr.net/npm/d3@7.9.0/dist/d3.min.js"></script><script src="https://cdn.jsdelivr.net/npm/markmap-view@0.18.12/dist/browser/index.js"></script><script src="https://cdn.jsdelivr.net/npm/markmap-toolbar@0.18.12/dist/index.js"></script><script>(r => {
              setTimeout(r);
            })(function renderToolbar() {
  const {
    markmap,
    mm
  } = window;
  const {
    el
  } = markmap.Toolbar.create(mm);
  el.setAttribute('style', 'position:absolute;bottom:20px;right:20px');
  document.body.append(el);
})</script><script>((getMarkmap, getOptions, root2, jsonOptions) => {
              const markmap = getMarkmap();
              window.mm = markmap.Markmap.create(
                "svg#mindmap",
                (getOptions || markmap.deriveOptions)(jsonOptions),
                root2
              );
              if (window.matchMedia("(prefers-color-scheme: dark)").matches) {
                document.documentElement.classList.add("markmap-dark");
              }
            })(() => window.markmap,null,{"content":"Large Language Models &#x2013; From Theory to Practical Applications","children":[{"content":"Introduction","children":[{"content":"What Are LLMs and Why Are They Important?","children":[{"content":"<strong>Language Model (LM):</strong>","children":[{"content":"A statistical model assigning probabilities to sequences of words/tokens.","children":[],"payload":{"tag":"li","lines":"20,21"}},{"content":"Core task: <strong>Next-token prediction</strong> (predicting the most likely next word/subword given the preceding sequence).<br>\n<img src=\"./imgs/1.png\" alt=\"Next-token prediction\">","children":[],"payload":{"tag":"li","lines":"21,23"}}],"payload":{"tag":"li","lines":"19,23"}},{"content":"<strong>Large:</strong>","children":[{"content":"Refers to the massive scale in parameters (trainable weights) &#x2014; billions or even trillions.","children":[],"payload":{"tag":"li","lines":"24,25"}},{"content":"Examples: GPT-2 (1.5B), GPT-3 (175B), Llama 2 (70B), PaLM 2.","children":[],"payload":{"tag":"li","lines":"25,26"}},{"content":"Also refers to the vast training datasets (terabytes of text).","children":[],"payload":{"tag":"li","lines":"26,27"}}],"payload":{"tag":"li","lines":"23,27"}},{"content":"<strong>Large Language Model (LLM):</strong>","children":[{"content":"A deep neural network (specifically, usually a Transformer) trained on massive text data.","children":[],"payload":{"tag":"li","lines":"28,29"}},{"content":"Designed to understand, generate, and respond to human-like text by learning patterns from data.","children":[],"payload":{"tag":"li","lines":"29,30"}},{"content":"A specific application of deep learning.<br>\n<img src=\"./imgs/2.png\" alt=\"AI/ML/DL/LLM hierarchy\">","children":[],"payload":{"tag":"li","lines":"30,32"}}],"payload":{"tag":"li","lines":"27,32"}},{"content":"<strong>Core Insight:</strong>","children":[{"content":"The seemingly <strong>simple objective of next-token prediction</strong>, when <strong>scaled massively</strong>, forces the model to <strong>learn complex language structures: grammar, syntax, semantics, context, facts,</strong> and <strong>even some reasoning capabilities</strong> to minimize prediction error across diverse texts.","children":[],"payload":{"tag":"li","lines":"33,35"}}],"payload":{"tag":"li","lines":"32,35"}}],"payload":{"tag":"h3","lines":"17,18"}},{"content":"A Brief History and Key Milestones","children":[{"content":"<strong>Statistical Era:</strong>","children":[{"content":"<strong>n-grams:</strong> Simple counts of word sequences (e.g., predicting the next word based on the previous 2-3 words). Limited context.","children":[],"payload":{"tag":"li","lines":"40,41"}}],"payload":{"tag":"li","lines":"39,41"}},{"content":"<strong>Vector Era:</strong>","children":[{"content":"<strong>Word2Vec, GloVe (circa 2013):</strong> Represent words as dense vectors (embeddings) capturing semantic relationships (e.g., king - man + woman &#x2248; queen). Static embeddings.","children":[],"payload":{"tag":"li","lines":"42,43"}}],"payload":{"tag":"li","lines":"41,43"}},{"content":"<strong>Sequential Era:</strong>","children":[{"content":"<strong>Recurrent Neural Networks (RNNs) &amp; Long Short-Term Memory (LSTMs):</strong> Process sequences word-by-word, maintaining a &apos;memory&apos; (hidden state). Better context handling but struggle with long-range dependencies and vanishing gradients.","children":[{"content":"Before the advent of transformer models, encoder-decoder RNNs were a popular choice for machine translation. The encoder takes a sequence of tokens from the source language as input, where a hidden state (an intermediate neural network layer) of the encoder encodes a compressed representation of the entire input sequence. Then, the decoder uses its current hidden state to begin the translation, token by token.<br>\n<img src=\"./imgs/3.png\" alt=\"Encoder-decoder RNN\">","children":[],"payload":{"tag":"li","lines":"45,47"}}],"payload":{"tag":"li","lines":"44,47"}}],"payload":{"tag":"li","lines":"43,47"}},{"content":"<strong>The Inflection Point (2017):</strong>","children":[{"content":"<strong>&quot;Attention Is All You Need&quot; paper:</strong> Introduced the <strong>Transformer architecture</strong>. Revolutionized NLP by enabling parallel processing and effective long-range dependency modeling via self-attention.","children":[],"payload":{"tag":"li","lines":"48,49"}}],"payload":{"tag":"li","lines":"47,49"}},{"content":"<strong>The Rise of Pretrained Models (2018+):</strong>","children":[{"content":"LLM evolution<br>\n<img src=\"./imgs/4.png\" alt=\"LLM evolution\">","children":[],"payload":{"tag":"li","lines":"50,52"}},{"content":"<strong>BERT (Bidirectional Encoder Representations from Transformers):</strong> Encoder-only model, excels at understanding tasks (classification, NER). Trained on masked language modeling (predicting hidden words).","children":[],"payload":{"tag":"li","lines":"52,53"}},{"content":"<strong>GPT (Generative Pre-trained Transformer):</strong> Decoder-only model, excels at text generation. Trained on next-token prediction.","children":[],"payload":{"tag":"li","lines":"53,54"}},{"content":"<strong>GPT-2, GPT-3, ChatGPT:</strong> Demonstrated remarkable generative capabilities and scaling effects.","children":[],"payload":{"tag":"li","lines":"54,55"}}],"payload":{"tag":"li","lines":"49,55"}},{"content":"<strong>Application Insight:</strong> The Transformer&apos;s parallelizability and effective context handling enabled training much larger models on much more data than previously feasible, leading to breakthroughs in performance and emergent abilities.","children":[],"payload":{"tag":"li","lines":"55,57"}}],"payload":{"tag":"h3","lines":"37,38"}},{"content":"Tokenization and Embeddings: The Foundation of LLMs","children":[{"content":"<strong>Tokenization:</strong>","children":[{"content":"Breaking raw text into smaller units (tokens) the model can process.","children":[],"payload":{"tag":"li","lines":"62,63"}},{"content":"Not always words: can be subwords or characters.","children":[],"payload":{"tag":"li","lines":"63,64"}},{"content":"<strong>Techniques:</strong>","children":[{"content":"<strong>Byte Pair Encoding (BPE):</strong> Common in GPT models. Starts with characters, iteratively merges frequent pairs. Handles unknown words gracefully by breaking them down.","children":[],"payload":{"tag":"li","lines":"65,66"}},{"content":"<strong>WordPiece:</strong> Used in BERT. Similar to BPE but merges based on likelihood.","children":[],"payload":{"tag":"li","lines":"66,67"}},{"content":"There are multiple methods of tokenization that break down the text to different sizes of components (words, subwords, characters, and bytes).<br>\n<img src=\"./imgs/5.png\" alt=\"Tokenization methods\">","children":[],"payload":{"tag":"li","lines":"67,69"}}],"payload":{"tag":"li","lines":"64,69"}}],"payload":{"tag":"li","lines":"61,69"}},{"content":"<strong>Embeddings:</strong>","children":[{"content":"Converting discrete tokens (or words) into dense numerical vectors.","children":[],"payload":{"tag":"li","lines":"70,71"}},{"content":"<strong>Purpose:</strong> Capture semantic meaning and relationships in a continuous space suitable for neural networks.","children":[],"payload":{"tag":"li","lines":"71,72"}},{"content":"<strong>Static vs. Contextual:</strong>","children":[{"content":"Word2Vec/GloVe: <strong>Static</strong> (same vector regardless of context).","children":[],"payload":{"tag":"li","lines":"73,74"}},{"content":"LLMs (BERT/GPT): <strong>Contextual</strong> (vector changes based on surrounding words, e.g., &quot;bank&quot; in &quot;river bank&quot; vs. &quot;money bank&quot;).","children":[{"content":"The values of embeddings represent properties that are used to represent words. We may oversimplify by imagining that dimensions represent concepts (which they don&#x2019;t), but it helps express the idea.<br>\n<img src=\"./imgs/6.png\" alt=\"Embedding dimensions/properties concept\">","children":[],"payload":{"tag":"li","lines":"75,77"}},{"content":"Embeddings of words that are similar will be close to each other in dimen sional space.<br>\n<img src=\"./imgs/7.png\" alt=\"Embedding dimensions/properties concept_2\">","children":[],"payload":{"tag":"li","lines":"77,79"}},{"content":"Embeddings can be created for different types of input.<br>\n<img src=\"./imgs/8.png\" alt=\"Different embedding types\">","children":[],"payload":{"tag":"li","lines":"79,81"}}],"payload":{"tag":"li","lines":"74,81"}}],"payload":{"tag":"li","lines":"72,81"}}],"payload":{"tag":"li","lines":"69,81"}},{"content":"<strong>Applications:</strong>","children":[{"content":"Input representation for LLMs.","children":[],"payload":{"tag":"li","lines":"82,83"}},{"content":"Key component in semantic search, text classification, clustering.","children":[],"payload":{"tag":"li","lines":"83,85"}}],"payload":{"tag":"li","lines":"81,85"}}],"payload":{"tag":"h3","lines":"59,60"}},{"content":"Difference from Traditional NLP","children":[{"content":"<table data-lines=\"89,96\">\n<thead data-lines=\"89,90\">\n<tr data-lines=\"89,90\">\n<th style=\"text-align:left\"><strong>Aspect</strong></th>\n<th style=\"text-align:left\"><strong>Traditional NLP Methods</strong></th>\n<th style=\"text-align:left\"><strong>Large Language Models (LLMs)</strong></th>\n</tr>\n</thead>\n<tbody data-lines=\"91,96\">\n<tr data-lines=\"91,92\">\n<td style=\"text-align:left\"><strong>1. Handling Complexity &amp; Context</strong></td>\n<td style=\"text-align:left\">&#x2022; Excelled at simpler classification/rule-based tasks.<br>&#x2022; <strong>Bag-of-Words:</strong> Ignored word order and context.<br>&#x2022; <strong>RNNs/LSTMs:</strong> Limited memory for long-range context; sequential bottleneck.<br>&#x2022; Struggled with complex generation, nuance, reasoning.</td>\n<td style=\"text-align:left\">&#x2022; Excel at complex understanding, generation, and reasoning.<br>&#x2022; <strong>Contextual Embeddings:</strong> Word meaning adapts to context.<br>&#x2022; <strong>Self-Attention:</strong> Considers all words simultaneously, capturing long-range dependencies effectively.<br>&#x2022; Handles diverse tasks within a single model.</td>\n</tr>\n<tr data-lines=\"92,93\">\n<td style=\"text-align:left\"><strong>2. Language Representation</strong></td>\n<td style=\"text-align:left\">&#x2022; <strong>Sparse Representations:</strong> (e.g., One-hot, TF-IDF) High-dimensional, computationally difficult.<br>&#x2022; <strong>Static Embeddings:</strong> (Word2Vec, GloVe) Dense but context-independent. Meaning captured but fixed.</td>\n<td style=\"text-align:left\">&#x2022; <strong>Dense, Contextual Embeddings:</strong> Rich, nuanced representations learned dynamically.<br>&#x2022; Model learns syntax, semantics, world knowledge implicitly from data.<br>&#x2022; Captures relationships between words across long distances.</td>\n</tr>\n<tr data-lines=\"93,94\">\n<td style=\"text-align:left\"><strong>3. Architecture &amp; Training</strong></td>\n<td style=\"text-align:left\">&#x2022; <strong>Manual Feature Engineering:</strong> Required human expertise to select relevant features.<br>&#x2022; <strong>RNNs/LSTMs:</strong> Sequential processing, hard to parallelize, vanishing gradients.<br>&#x2022; <strong>Smaller Datasets:</strong> Limited by computational constraints.</td>\n<td style=\"text-align:left\">&#x2022; <strong>Transformer Architecture:</strong> Based on self-attention, highly parallelizable.<br>&#x2022; <strong>End-to-End Learning:</strong> Minimal feature engineering needed.<br>&#x2022; <strong>Massive Datasets &amp; Compute:</strong> Trained on web-scale text using large GPU clusters.<br>&#x2022; <strong>Self-Supervised Pre-training:</strong> Learns from raw text.</td>\n</tr>\n<tr data-lines=\"94,95\">\n<td style=\"text-align:left\"><strong>4. Generalization &amp; Scope</strong></td>\n<td style=\"text-align:left\">&#x2022; <strong>Task-Specific Models:</strong> Required separate training for each task (translation, sentiment, etc.).<br>&#x2022; Limited ability to generalize to new, unseen tasks without retraining.</td>\n<td style=\"text-align:left\">&#x2022; <strong>General-Purpose Foundation Models:</strong> Pre-trained once, then fine-tuned or prompted for many tasks.<br>&#x2022; <strong>Zero-Shot &amp; Few-Shot Learning:</strong> Can perform tasks with no or very few examples.<br>&#x2022; <strong>Emergent Abilities:</strong> Displays capabilities not explicitly trained for (e.g., arithmetic).</td>\n</tr>\n<tr data-lines=\"95,96\">\n<td style=\"text-align:left\"><strong>5. Performance</strong></td>\n<td style=\"text-align:left\">&#x2022; State-of-the-art for specific, narrow tasks pre-Transformer.<br>&#x2022; Performance plateaued on complex tasks.</td>\n<td style=\"text-align:left\">&#x2022; State-of-the-art across a wide range of NLP benchmarks.<br>&#x2022; Performance continues to improve with scale (data, parameters, compute).</td>\n</tr>\n</tbody>\n</table>","children":[],"payload":{"tag":"table","lines":"89,96"}}],"payload":{"tag":"h3","lines":"87,88"}}],"payload":{"tag":"h2","lines":"15,16"}},{"content":"The Core Architecture: The Transformer (Review Last Week Lecture)","children":[{"content":"The Problem with RNNs/LSTMs (Recap)","children":[{"content":"<strong>Sequential Processing:</strong> Cannot process words in parallel; slow for long sequences.","children":[],"payload":{"tag":"li","lines":"103,104"}},{"content":"<strong>Information Bottleneck:</strong> Tries to compress the entire past sequence meaning into a fixed-size hidden state. Information loss for long dependencies.","children":[],"payload":{"tag":"li","lines":"104,105"}},{"content":"<strong>Vanishing/Exploding Gradients:</strong> Difficulty training very deep sequential models.","children":[{"content":"RNNs are sequential models that process text one token at a time, and each token is dependent on the previous tokens. This means that the model cannot process tokens in parallel, and it is slow for long sequences.<br>\n<img src=\"./imgs/9.png\" alt=\"RNN bottleneck\">","children":[],"payload":{"tag":"li","lines":"106,109"}}],"payload":{"tag":"li","lines":"105,109"}}],"payload":{"tag":"h3","lines":"101,102"}},{"content":"The Core Concept: Self-Attention","children":[{"content":"The Revolution: Processing Words in Parallel","children":[{"content":"<strong>Big Idea:</strong> Instead of sequence, treat input as a <strong>set of tokens</strong>. Each token can directly look at (&quot;attend to&quot;) all other tokens in the input to determine its own contextualized representation.","children":[{"content":"Instead of processing text one token at a time, the model can process all tokens in parallel. This means that the model can process longer sequences faster.<br>\n<img src=\"./imgs/10.png\" alt=\"Self-attention\">","children":[],"payload":{"tag":"li","lines":"116,118"}}],"payload":{"tag":"li","lines":"115,118"}},{"content":"<strong>Analogy:</strong> At a meeting, instead of listening sequentially, you can instantly gauge the importance of everyone&apos;s contribution relative to your current point.","children":[],"payload":{"tag":"li","lines":"118,120"}}],"payload":{"tag":"h4","lines":"113,114"}},{"content":"Mechanism (Scaled Dot-Product Attention)","children":[{"content":"For each token, create three vectors via learned linear projections (Weight matrices Wq, Wk, Wv):","children":[{"content":"<strong>Query (Q):</strong> Represents the current token&apos;s request for information (&quot;What am I looking for?&quot;).","children":[],"payload":{"tag":"li","lines":"123,124"}},{"content":"<strong>Key (K):</strong> Represents what information other tokens <em>have</em> (&quot;What kind of information do I hold?&quot;).","children":[],"payload":{"tag":"li","lines":"124,125"}},{"content":"<strong>Value (V):</strong> Represents the actual information content other tokens <em>provide</em> (&quot;Here is the information I offer.&quot;).","children":[],"payload":{"tag":"li","lines":"125,126"}}],"payload":{"tag":"li","lines":"122,126"}},{"content":"<strong>Steps:</strong>","children":[{"content":"<strong>Calculate Attention Scores:</strong> Dot product between the Query of the current token and the Keys of all tokens (including itself). Measures relevance/similarity.<pre data-lines=\"128,131\"><code class=\"language-math\">Score(Q, K) = \\frac{Q * K^T}{\\sqrt{d_k}}\n</code></pre>\n<img src=\"./imgs/11.png\" alt=\"Self-attention scores\"><br>\n<img src=\"./imgs/12.png\" alt=\"Self-attention scores_2\">","children":[],"payload":{"tag":"li","lines":"127,133"}},{"content":"<strong>Normalize Scores:</strong> Apply Softmax to scores to get <strong>Attention Weights</strong> (probabilities summing to 1).<pre data-lines=\"134,137\"><code class=\"language-math\">Weights = Softmax(Scores)\n</code></pre>\n<img src=\"./imgs/13.png\" alt=\"Self-attention weights\"><br>\n<img src=\"./imgs/14.png\" alt=\"Self-attention weights_2\">","children":[],"payload":{"tag":"li","lines":"133,139"}},{"content":"<strong>Compute Context Vector:</strong> Weighted sum of Value vectors, using Attention Weights.<pre data-lines=\"140,143\"><code class=\"language-math\">Context = Weights \\times V\n</code></pre>\n<img src=\"./imgs/15.png\" alt=\"Self-attention context\"><br>\n<img src=\"./imgs/16.png\" alt=\"Self-attention context_2\"><br>\nThis context vector is the output for the current token.","children":[],"payload":{"tag":"li","lines":"139,147"}}],"payload":{"tag":"li","lines":"126,147"}}],"payload":{"tag":"h4","lines":"120,121"}}],"payload":{"tag":"h3","lines":"111,112"}},{"content":"The Transformer Block","children":[{"content":"Components","children":[{"content":"<strong>Multi-Head Attention:</strong>","children":[{"content":"Runs the self-attention mechanism multiple times in parallel with different learned projection matrices (Wq, Wk, Wv for each &quot;head&quot;).","children":[],"payload":{"tag":"li","lines":"154,155"}},{"content":"Allows the model to jointly attend to information from different representation subspaces (e.g., focusing on syntax in one head, semantics in another).","children":[],"payload":{"tag":"li","lines":"155,156"}},{"content":"Outputs are concatenated and linearly projected.<br>\n<img src=\"./imgs/17.png\" alt=\"Multi-head attention\">","children":[],"payload":{"tag":"li","lines":"156,158"}}],"payload":{"tag":"li","lines":"153,158"}},{"content":"<strong>Add &amp; Norm (Layer Normalization):</strong> Adds the input of the sub-layer (residual connection) to its output, then normalizes. Stabilizes training, helps with deep networks.<br>\n<img src=\"./imgs/18.png\" alt=\"Add &amp; Norm\">","children":[],"payload":{"tag":"li","lines":"158,160"}},{"content":"<strong>Feed-Forward Network (FFN):</strong>","children":[{"content":"Applied independently to each token&apos;s representation after attention.","children":[],"payload":{"tag":"li","lines":"161,162"}},{"content":"Typically two linear layers with a non-linear activation (e.g., ReLU, GELU).","children":[],"payload":{"tag":"li","lines":"162,163"}},{"content":"Processes the information gathered by the attention layer, adds modeling capacity.","children":[],"payload":{"tag":"li","lines":"163,164"}}],"payload":{"tag":"li","lines":"160,164"}},{"content":"<strong>Positional Encodings:</strong> Since self-attention ignores order, these vectors are added to the input embeddings to provide information about the position of tokens in the sequence. Can be fixed (sine/cosine) or learned.","children":[],"payload":{"tag":"li","lines":"164,166"}}],"payload":{"tag":"h4","lines":"151,152"}},{"content":"Architecture Variants (Recap)","children":[{"content":"<strong>Encoder-Decoder (Original Transformer, T5, BART):</strong> Sequence-to-sequence tasks (e.g., Translation, Summarization). Encoder processes input, Decoder generates output attending to encoder output.<br>\n<img src=\"./imgs/19.png\" alt=\"Encoder-Decoder\">","children":[],"payload":{"tag":"li","lines":"168,170"}},{"content":"<strong>Decoder-Only (GPT series, Llama, PaLM):</strong> Autoregressive generation. Each token attends to previous tokens (causal masking). Dominant for generative LLMs.<br>\n<img src=\"./imgs/20.png\" alt=\"Decoder-Only\">","children":[],"payload":{"tag":"li","lines":"170,172"}},{"content":"<strong>Encoder-Only (BERT, RoBERTa):</strong> Bidirectional context understanding. Good for analysis tasks (Classification, NER, Embeddings). Output is contextualized representations, not generated text.<br>\n<img src=\"./imgs/21.png\" alt=\"Encoder-Only\">","children":[],"payload":{"tag":"li","lines":"172,175"}}],"payload":{"tag":"h4","lines":"166,167"}}],"payload":{"tag":"h3","lines":"149,150"}}],"payload":{"tag":"h2","lines":"99,100"}},{"content":"The &quot;Large&quot;: Scaling Laws &amp; Emergence","children":[{"content":"The Scaling Laws (Kaplan et al., Hoffmann et al.)","children":[{"content":"<strong>Discovery:</strong> LLM performance (measured by loss on unseen text) scales predictably as a power-law with increases in:","children":[{"content":"1. <strong>Model Size (Parameters, N):</strong> Number of trainable weights.","children":[],"payload":{"tag":"li","lines":"182,183","listIndex":1}},{"content":"2. <strong>Dataset Size (Tokens, D):</strong> Amount of training text.","children":[],"payload":{"tag":"li","lines":"183,184","listIndex":2}},{"content":"3. <strong>Compute (FLOPs):</strong> Total floating-point operations used for training.","children":[],"payload":{"tag":"li","lines":"184,185","listIndex":3}}],"payload":{"tag":"li","lines":"181,185"}},{"content":"<strong>Key Insight:</strong> For optimal performance at a given compute budget, model size and dataset size should be scaled together (Chinchilla scaling laws). Training smaller models on much more data is often better than huge models on less data.","children":[],"payload":{"tag":"li","lines":"185,186"}},{"content":"<strong>Engineering Impact:</strong> Enabled researchers to forecast the performance gains from scaling, justifying the massive investments needed for models like GPT-3/4.","children":[],"payload":{"tag":"li","lines":"186,188"}}],"payload":{"tag":"h3","lines":"179,180"}},{"content":"Emergent Abilities","children":[{"content":"<strong>Definition:</strong> Capabilities not present in smaller models that <em>emerge</em> abruptly at larger scales. They are not explicitly designed or trained for.","children":[],"payload":{"tag":"li","lines":"192,193"}},{"content":"<strong>Examples:</strong>","children":[{"content":"<strong>Few-Shot / Zero-Shot Learning:</strong> Performing tasks based on instructions/examples in the prompt without fine-tuning.","children":[],"payload":{"tag":"li","lines":"194,195"}},{"content":"<strong>Arithmetic:</strong> Performing basic math operations.","children":[],"payload":{"tag":"li","lines":"195,196"}},{"content":"<strong>Reasoning:</strong> Step-by-step logical deduction (Chain-of-Thought).","children":[],"payload":{"tag":"li","lines":"196,197"}},{"content":"<strong>Common Sense:</strong> Answering questions requiring implicit world knowledge.","children":[],"payload":{"tag":"li","lines":"197,198"}}],"payload":{"tag":"li","lines":"193,198"}},{"content":"<strong>The Mystery &amp; Hypothesis:</strong> These abilities likely arise because mastering next-token prediction on diverse, complex web-scale data implicitly forces the model to learn underlying structures, facts, and reasoning patterns present in the data.","children":[],"payload":{"tag":"li","lines":"198,200"}}],"payload":{"tag":"h3","lines":"190,191"}}],"payload":{"tag":"h2","lines":"177,178"}},{"content":"Using Pretrained LLMs","children":[{"content":"Generative Models (GPT-like) and Prompt Engineering","children":[{"content":"Core Mechanism: Autoregressive Generation","children":[{"content":"<strong>Objective:</strong> Given a sequence of tokens (prompt), predict the most probable <em>next</em> token.","children":[],"payload":{"tag":"li","lines":"208,209"}},{"content":"Append the predicted token to the sequence and repeat to generate text.<br>\n<img src=\"./imgs/22.png\" alt=\"Autoregressive generation\">","children":[],"payload":{"tag":"li","lines":"209,212"}}],"payload":{"tag":"h4","lines":"206,207"}},{"content":"Prompt Engineering: Guiding the Generator","children":[{"content":"The art and science of crafting effective input prompts to elicit desired outputs from an LLM.","children":[],"payload":{"tag":"li","lines":"214,216"}}],"payload":{"tag":"h4","lines":"212,213"}},{"content":"Basic Components of a Prompt","children":[{"content":"<strong>Instruction:</strong> Clear command telling the model what task to perform (e.g., &quot;Summarize this text&quot;, &quot;Translate to French&quot;, &quot;Write a poem&quot;).","children":[],"payload":{"tag":"li","lines":"218,219"}},{"content":"<strong>Context:</strong> Relevant background information the model might need (e.g., the text to be summarized, previous conversation turns).","children":[],"payload":{"tag":"li","lines":"219,220"}},{"content":"<strong>Input Data:</strong> The specific data the instruction applies to.","children":[],"payload":{"tag":"li","lines":"220,221"}},{"content":"<strong>Output Indicator/Format:</strong> Specify how the output should look (e.g., &quot;Output as a JSON&quot;, &quot;List the main points&quot;, &quot;Sentiment: &quot;).","children":[],"payload":{"tag":"li","lines":"221,223"}}],"payload":{"tag":"h4","lines":"216,217"}},{"content":"Shot Learning (In-Context Learning)","children":[{"content":"<strong>Zero-Shot:</strong> Provide only the instruction, rely on the model&apos;s pre-trained knowledge. (e.g., &quot;Translate &apos;hello&apos; to French.&quot;)","children":[],"payload":{"tag":"li","lines":"225,226"}},{"content":"<strong>Few-Shot:</strong> Provide a few examples of the task within the prompt to guide the model. (e.g., &quot;sea otter =&gt; loutre de mer\\ncheese =&gt; fromage\\nhello =&gt; ?&quot;)","children":[],"payload":{"tag":"li","lines":"226,227"}},{"content":"<img src=\"./imgs/23.png\" alt=\"Zero-shot and few-shot learning\">","children":[],"payload":{"tag":"li","lines":"227,229"}}],"payload":{"tag":"h4","lines":"223,224"}},{"content":"Advanced Prompting Techniques","children":[{"content":"<strong>Chain-of-Thought (CoT) Prompting:</strong> Encourage step-by-step reasoning by showing examples or using phrases like &quot;Let&apos;s think step-by-step.&quot; Helps with math, logic, complex Q&amp;A.<br>\n<img src=\"./imgs/24.png\" alt=\"Chain-of-Thought (CoT) Prompting\">","children":[],"payload":{"tag":"li","lines":"231,233"}},{"content":"<strong>Self-Consistency:</strong> Generate multiple reasoning paths (CoT) with randomness (temperature &gt; 0), then take the majority answer. Improves robustness, especially for reasoning tasks.<br>\n<img src=\"./imgs/25.png\" alt=\"Self-Consistency\">","children":[],"payload":{"tag":"li","lines":"233,235"}},{"content":"<strong>Tree-of-Thought (ToT):</strong> More advanced; explores multiple reasoning paths, evaluates intermediate steps.<br>\n<img src=\"./imgs/26.png\" alt=\"Tree-of-Thought (ToT)\">","children":[],"payload":{"tag":"li","lines":"235,238"}}],"payload":{"tag":"h4","lines":"229,230"}},{"content":"Output Control: Sampling Parameters","children":[{"content":"Parameters adjust how the <em>next token</em> is chosen from the probability distribution predicted by the model:","children":[{"content":"<strong><code>temperature</code>:</strong> Scales logits before softmax.","children":[{"content":"Low (~0.1): More deterministic, focused, less creative (picks high-probability tokens).","children":[],"payload":{"tag":"li","lines":"242,243"}},{"content":"High (~1.0+): More random, creative, diverse, potentially less coherent (gives lower-probability tokens a chance).","children":[],"payload":{"tag":"li","lines":"243,244"}},{"content":"A higher temperature will result in a more random distribution of tokens.<br>\n<img src=\"./imgs/27.png\" alt=\"Temperature\">","children":[],"payload":{"tag":"li","lines":"244,246"}}],"payload":{"tag":"li","lines":"241,246"}},{"content":"<strong><code>top_p</code> (Nucleus Sampling):</strong> Selects from the smallest set of tokens whose cumulative probability exceeds <code>p</code>. E.g., <code>top_p=0.9</code> considers only the most probable tokens that add up to 90% probability. Balances diversity and coherence.<br>\n<img src=\"./imgs/28.png\" alt=\"Top-p sampling\">","children":[],"payload":{"tag":"li","lines":"246,248"}},{"content":"<strong><code>top_k</code>:</strong> Selects from the top <code>k</code> most probable tokens. Simpler alternative to <code>top_p</code>.","children":[],"payload":{"tag":"li","lines":"248,249"}},{"content":"<strong><code>max_tokens</code>/<code>max_new_tokens</code>:</strong> Limits the length of the generated response.","children":[],"payload":{"tag":"li","lines":"249,251"}}],"payload":{"tag":"li","lines":"240,251"}}],"payload":{"tag":"h4","lines":"238,239"}}],"payload":{"tag":"h3","lines":"204,205"}},{"content":"Representation Models (BERT-like) and Their Applications","children":[{"content":"Encoder-only Architecture (Recap)","children":[{"content":"Processes the entire input sequence simultaneously (bidirectional context).","children":[],"payload":{"tag":"li","lines":"257,258"}},{"content":"Output is a set of contextualized embeddings for each input token, not generated text.","children":[],"payload":{"tag":"li","lines":"258,259"}},{"content":"Excels at understanding meaning and relationships within the input text.","children":[],"payload":{"tag":"li","lines":"259,261"}}],"payload":{"tag":"h4","lines":"255,256"}},{"content":"Applications","children":[{"content":"<strong>Text Classification:</strong>","children":[{"content":"Assigning predefined labels/categories to text (e.g., sentiment, topic, intent).","children":[],"payload":{"tag":"li","lines":"265,266"}},{"content":"<img src=\"./imgs/29.png\" alt=\"Text Classification\">","children":[],"payload":{"tag":"li","lines":"266,267"}},{"content":"<strong>Method:</strong>","children":[{"content":"1. Obtain contextual embeddings for the input text (often using the special <code>[CLS]</code> token&apos;s embedding from BERT, or pooling token embeddings).","children":[],"payload":{"tag":"li","lines":"268,269","listIndex":1}},{"content":"2. Feed these embeddings into a simple classifier (e.g., Logistic Regression, small Feed-Forward Network) trained on labeled data.","children":[],"payload":{"tag":"li","lines":"269,271","listIndex":2}}],"payload":{"tag":"li","lines":"267,271"}}],"payload":{"tag":"h5","lines":"263,264"}},{"content":"<strong>Semantic Search:</strong>","children":[{"content":"Finding documents relevant by <em>meaning</em> rather than just matching keywords.","children":[],"payload":{"tag":"li","lines":"273,274"}},{"content":"<img src=\"./imgs/30.png\" alt=\"Semantic Search\">","children":[],"payload":{"tag":"li","lines":"274,275"}},{"content":"<strong>Method:</strong>","children":[{"content":"1. Pre-compute embeddings for all documents in a corpus and store them (e.g., in a vector database).","children":[],"payload":{"tag":"li","lines":"276,277","listIndex":1}},{"content":"2. Embed the user&apos;s search query using the same model.","children":[],"payload":{"tag":"li","lines":"277,278","listIndex":2}},{"content":"3. Find document embeddings closest to the query embedding in the vector space (using measures like cosine similarity or Euclidean distance).","children":[],"payload":{"tag":"li","lines":"278,279","listIndex":3}}],"payload":{"tag":"li","lines":"275,279"}},{"content":"<strong>Contrast with Keyword Search:</strong> Keyword search misses synonyms, related concepts; semantic search captures them.","children":[],"payload":{"tag":"li","lines":"279,281"}}],"payload":{"tag":"h5","lines":"271,272"}}],"payload":{"tag":"h4","lines":"261,262"}}],"payload":{"tag":"h3","lines":"253,254"}},{"content":"Retrieval-Augmented Generation (RAG)","children":[{"content":"Motivation: Addressing LLM Weaknesses","children":[{"content":"<strong>Hallucinations:</strong> Generative LLMs can invent facts or details not supported by their training data.","children":[],"payload":{"tag":"li","lines":"287,288"}},{"content":"<strong>Outdated Knowledge:</strong> Models are static snapshots of their training data; they don&apos;t know about events after their training cut-off.","children":[],"payload":{"tag":"li","lines":"288,289"}},{"content":"<strong>Lack of Domain Specificity:</strong> A general model may lack deep knowledge of a specific niche or private dataset.","children":[],"payload":{"tag":"li","lines":"289,291"}}],"payload":{"tag":"h4","lines":"285,286"}},{"content":"RAG Concept: Grounding Generation with External Knowledge","children":[{"content":"Combine the strengths of <strong>retrieval</strong> (finding relevant information from a knowledge source) and <strong>generation</strong> (creating fluent, coherent text).","children":[],"payload":{"tag":"li","lines":"293,294"}},{"content":"<img src=\"./imgs/31.png\" alt=\"RAG Concept\">","children":[],"payload":{"tag":"li","lines":"294,295"}},{"content":"Provide the LLM with relevant, up-to-date context <em>at inference time</em> to improve its responses.","children":[],"payload":{"tag":"li","lines":"295,297"}}],"payload":{"tag":"h4","lines":"291,292"}},{"content":"Workflow","children":[{"content":"1. <strong>User Query:</strong> Receive the user&apos;s question or prompt.","children":[],"payload":{"tag":"li","lines":"299,300","listIndex":1}},{"content":"2. <strong>Retrieval:</strong> Use the query (or a transformed version) to search an external knowledge base (e.g., internal documents, Wikipedia, web search results) using semantic search (or keyword search, or hybrid). Retrieve the most relevant text chunks/documents.","children":[],"payload":{"tag":"li","lines":"300,301","listIndex":2}},{"content":"3. <strong>Augmentation:</strong> Construct a new prompt for the generative LLM, incorporating the original query <em>and</em> the retrieved documents as context.","children":[],"payload":{"tag":"li","lines":"301,302","listIndex":3}},{"content":"4. <strong>Generation:</strong> The LLM generates an answer based <em>primarily</em> on the provided context, synthesized into a coherent response.","children":[],"payload":{"tag":"li","lines":"302,304","listIndex":4}}],"payload":{"tag":"h4","lines":"297,298"}},{"content":"Applications &amp; Benefits","children":[{"content":"<strong>Fact-Checking / Reduced Hallucination:</strong> Answers are based on retrieved evidence.","children":[],"payload":{"tag":"li","lines":"306,307"}},{"content":"<strong>Access to Current Information:</strong> Can query real-time sources (like web search).","children":[],"payload":{"tag":"li","lines":"307,308"}},{"content":"<strong>Domain-Specific Q&amp;A:</strong> Chat with your own documents (PDFs, internal wiki, codebases) without retraining the LLM.","children":[],"payload":{"tag":"li","lines":"308,309"}},{"content":"<strong>Citations:</strong> Can potentially cite sources used in the answer.","children":[],"payload":{"tag":"li","lines":"309,310"}},{"content":"<strong>Demo Idea:</strong> Conceptual walk-through of answering a question using a small text document via RAG.","children":[],"payload":{"tag":"li","lines":"310,312"}}],"payload":{"tag":"h4","lines":"304,305"}}],"payload":{"tag":"h3","lines":"283,284"}}],"payload":{"tag":"h2","lines":"202,203"}},{"content":"The Training Pipeline: Making LLMs Helpful &amp; Safe","children":[{"content":"Phase 1: Pre-training (Creating the Base Model)","children":[{"content":"<strong>Objective:</strong> Learn general language understanding and world knowledge. <strong>Predict the next token.</strong>","children":[],"payload":{"tag":"li","lines":"318,319"}},{"content":"<strong>Data:</strong> Massive, diverse corpora of unlabeled text (Common Crawl, books, code, Wikipedia). Billions to trillions of tokens.","children":[{"content":"The pretraining dataset of the popular GPT-3 LLM<br>\n<img src=\"./imgs/32.png\" alt=\"GPT-3 pretraining dataset\">","children":[],"payload":{"tag":"li","lines":"320,322"}}],"payload":{"tag":"li","lines":"319,322"}},{"content":"<strong>Method:</strong> Self-supervised learning (next-token prediction). Model learns patterns implicitly.<br>\n<img src=\"./imgs/33.png\" alt=\"Pre-training\">","children":[],"payload":{"tag":"li","lines":"322,324"}},{"content":"<strong>Result:</strong> A <strong>Base Model</strong> (e.g., GPT-3 base, Llama 2 base).<br>\n<img src=\"./imgs/34.png\" alt=\"Base Model\">","children":[],"payload":{"tag":"li","lines":"324,326"}},{"content":"<strong>Characteristics:</strong> Good at text completion, has broad knowledge, but is not an &quot;assistant.&quot; May generate undesirable, unsafe, or unhelpful text. Does not inherently follow instructions well.","children":[{"content":"Example: Prompt &quot;What is the capital of France?&quot; -&gt; Base Model Completion: &quot;...is a question often asked by tourists visiting Europe. What is the population of France?...&quot;","children":[],"payload":{"tag":"li","lines":"327,329"}}],"payload":{"tag":"li","lines":"326,329"}}],"payload":{"tag":"h3","lines":"316,317"}},{"content":"Phase 2: Supervised Fine-Tuning (SFT) / Instruction Tuning","children":[{"content":"<strong>Objective:</strong> Teach the base model to follow instructions and respond in a helpful, conversational manner.","children":[],"payload":{"tag":"li","lines":"333,334"}},{"content":"<strong>Data:</strong> High-quality dataset of <strong>(Instruction Prompt, Desired Response)</strong> pairs. Often human-curated or augmented. Thousands to millions of examples.<br>\n<img src=\"./imgs/35.png\" alt=\"SFT dataset\">","children":[],"payload":{"tag":"li","lines":"334,336"}},{"content":"<strong>Method:</strong> Continue training the base model using the same next-token prediction objective, but only on the structured instruction-response data. The model learns to generate the &quot;Desired Response&quot; when given the &quot;Instruction Prompt&quot;.<br>\n<img src=\"./imgs/36.png\" alt=\"SFT\">","children":[],"payload":{"tag":"li","lines":"336,338"}},{"content":"<strong>Result:</strong> An <strong>Instruction-Tuned Model</strong> (e.g., InstructGPT, Llama 2 Chat before RLHF/DPO).","children":[],"payload":{"tag":"li","lines":"338,339"}},{"content":"<strong>Characteristics:</strong> Better at following commands, answering questions directly, adopting specific formats or personas. Still may generate unsafe or low-quality responses occasionally.","children":[],"payload":{"tag":"li","lines":"339,341"}}],"payload":{"tag":"h3","lines":"331,332"}},{"content":"Phase 3: Alignment (Creating the Assistant Model)","children":[{"content":"Technique 1: Reinforcement Learning from Human Feedback (RLHF)","children":[{"content":"1. <strong>Collect Human Preference Data:</strong> For a given prompt, generate multiple responses from the SFT model. Have human labelers rank these responses from best to worst.<br>\n<img src=\"./imgs/37.png\" alt=\"RLHF\">","children":[],"payload":{"tag":"li","lines":"350,352","listIndex":1}},{"content":"2. <strong>Train a Reward Model (RM):</strong> Train a separate model (often initialized from the SFT model) to predict the human preference score for a given (prompt, response) pair, based on the ranking data.<br>\n<img src=\"./imgs/38.png\" alt=\"RM\">","children":[],"payload":{"tag":"li","lines":"352,354","listIndex":2}},{"content":"3. <strong>Fine-tune the SFT Model via Reinforcement Learning (RL):</strong> Use an RL algorithm like Proximal Policy Optimization (PPO) to update the SFT model&apos;s parameters. The &quot;reward&quot; signal comes from the trained Reward Model. The model learns to generate responses that maximize the predicted human preference score.<br>\n<img src=\"./imgs/39.png\" alt=\"RL\">","children":[],"payload":{"tag":"li","lines":"354,357","listIndex":3}}],"payload":{"tag":"h4","lines":"348,349"}},{"content":"Technique 2: Direct Preference Optimization (DPO)","children":[{"content":"<strong>Motivation:</strong> RLHF is complex and can be unstable to train (requires training multiple models).","children":[],"payload":{"tag":"li","lines":"359,360"}},{"content":"<strong>Method:</strong> A simpler, more direct approach. Uses the same preference data (pairs of chosen vs. rejected responses) but formulates the objective directly in terms of optimizing the language model&apos;s likelihood of generating the preferred response over the rejected one, without needing an explicit reward model or RL. Often uses a frozen copy of the SFT model as a reference.<br>\n<img src=\"./imgs/40.png\" alt=\"DPO\">","children":[],"payload":{"tag":"li","lines":"360,362"}},{"content":"<strong>Result:</strong> An <strong>Aligned Model</strong> (e.g., ChatGPT, Llama 2 Chat).","children":[],"payload":{"tag":"li","lines":"362,363"}},{"content":"<strong>Characteristics:</strong> Generally safer, more helpful, follows instructions more reliably, and better aligns with user expectations compared to just SFT models.","children":[],"payload":{"tag":"li","lines":"363,365"}}],"payload":{"tag":"h4","lines":"357,358"}}],"payload":{"tag":"h3","lines":"343,344"}}],"payload":{"tag":"h2","lines":"314,315"}},{"content":"Fine-tuning and Customizing LLMs","children":[{"content":"Why Fine-tune? (Beyond SFT/Alignment)","children":[{"content":"<strong>Domain Adaptation:</strong> Improve performance on text specific to a field (e.g., medical, legal, finance) where jargon or context differs from general web text.","children":[],"payload":{"tag":"li","lines":"371,372"}},{"content":"<strong>Task Specialization:</strong> Enhance capability for a specific downstream task (e.g., sentiment analysis of <em>your</em> customer reviews, summarizing <em>your</em> meeting notes).","children":[],"payload":{"tag":"li","lines":"372,373"}},{"content":"<strong>Style/Tone Adaptation:</strong> Train the model to generate text in a specific voice or format (e.g., mimic a specific author, output structured JSON).","children":[],"payload":{"tag":"li","lines":"373,374"}},{"content":"<strong>Improved Instruction Following:</strong> Make the model better at adhering to specific, complex instructions relevant to your use case.","children":[],"payload":{"tag":"li","lines":"374,376"}}],"payload":{"tag":"h3","lines":"369,370"}},{"content":"Parameter-Efficient Fine-tuning (PEFT)","children":[{"content":"Popular PEFT Methods:","children":[{"content":"<strong>Adapters:</strong> Insert small, trainable neural network modules between existing layers of the frozen pre-trained model.<br>\n<img src=\"./imgs/41.png\" alt=\"Adapters\">","children":[],"payload":{"tag":"li","lines":"390,392"}},{"content":"<strong>LoRA (Low-Rank Adaptation):</strong> Instead of adding new modules, LoRA learns low-rank <em>updates</em> to the existing weight matrices (e.g., attention projections). Freezes original weights <code>W</code>, trains small matrices <code>A</code> and <code>B</code> such that the update is <code>W + BA</code>. Very parameter-efficient.<br>\n<img src=\"./imgs/42.png\" alt=\"LoRA\">","children":[],"payload":{"tag":"li","lines":"392,394"}},{"content":"<strong>QLoRA (Quantized LoRA):</strong> Further reduces memory by quantizing the frozen base model weights (e.g., to 4-bit precision) while training the LoRA adapters in higher precision. Enables fine-tuning even larger models on limited hardware.<br>\n<img src=\"./imgs/43.png\" alt=\"QLoRA\">","children":[],"payload":{"tag":"li","lines":"394,396"}},{"content":"<strong>Application:</strong> Enables customization of powerful open-source LLMs (like Llama, Mistral) for specific needs on accessible hardware.","children":[],"payload":{"tag":"li","lines":"396,398"}}],"payload":{"tag":"h4","lines":"388,389"}}],"payload":{"tag":"h3","lines":"378,379"}}],"payload":{"tag":"h2","lines":"367,368"}},{"content":"Capabilities, Limitations, and Societal Impact","children":[{"content":"What LLMs Are Good At","children":[{"content":"<strong>Text Generation:</strong> Creating fluent, coherent, and often creative text (prose, poetry, code, scripts).","children":[],"payload":{"tag":"li","lines":"404,405"}},{"content":"<strong>Language Understanding:</strong> Summarization, translation, question answering, sentiment analysis, information extraction.","children":[],"payload":{"tag":"li","lines":"405,406"}},{"content":"<strong>Knowledge Recall:</strong> Accessing and synthesizing information learned during pre-training (though potentially outdated or incorrect).","children":[],"payload":{"tag":"li","lines":"406,407"}},{"content":"<strong>Pattern Recognition &amp; Synthesis:</strong> Identifying complex patterns in text and generating text that follows those patterns (e.g., style imitation, format adherence).","children":[],"payload":{"tag":"li","lines":"407,408"}},{"content":"<strong>Few-Shot Learning:</strong> Adapting to new tasks quickly with minimal examples provided in the prompt.","children":[],"payload":{"tag":"li","lines":"408,410"}}],"payload":{"tag":"h3","lines":"402,403"}},{"content":"The &quot;Soft Underbelly&quot; (Limitations &amp; Risks)","children":[{"content":"<strong>Hallucinations / Confabulation:</strong> Generating plausible but factually incorrect or nonsensical information with high confidence. Not grounded in real-time truth.","children":[],"payload":{"tag":"li","lines":"414,415"}},{"content":"<strong>Reasoning Failures:</strong> Struggle with complex multi-step logic, mathematics, causality, and planning. Often rely on surface patterns rather than deep understanding.","children":[],"payload":{"tag":"li","lines":"415,416"}},{"content":"<strong>Bias Amplification:</strong> Models learn and can perpetuate societal biases (gender, race, stereotypes) present in the massive, unfiltered training data.","children":[],"payload":{"tag":"li","lines":"416,417"}},{"content":"<strong>Memorization &amp; Privacy:</strong> Can sometimes regurgitate sensitive or copyrighted information verbatim from their training data.","children":[],"payload":{"tag":"li","lines":"417,418"}},{"content":"<strong>Outdated Knowledge:</strong> Static models don&apos;t learn continuously; information becomes stale after training. (RAG mitigates this).","children":[],"payload":{"tag":"li","lines":"418,419"}},{"content":"<strong>Lack of Common Sense / World Model:</strong> Debate continues on whether LLMs truly understand concepts or just manipulate linguistic patterns. Often fail on novel situations requiring basic physical or social reasoning.","children":[],"payload":{"tag":"li","lines":"419,420"}},{"content":"<strong>Brittleness / Sensitivity to Prompting:</strong> Small changes in prompt wording can lead to drastically different outputs.","children":[],"payload":{"tag":"li","lines":"420,422"}}],"payload":{"tag":"h3","lines":"412,413"}},{"content":"Ethics and Societal Impact","children":[{"content":"The Big Questions &amp; Concerns","children":[{"content":"<strong>Job Displacement / Labor Market Disruption:</strong> Automation of tasks involving writing, coding, customer service, analysis, content creation. Need for workforce adaptation.","children":[],"payload":{"tag":"li","lines":"428,429"}},{"content":"<strong>Misinformation &amp; Disinformation:</strong> Potential for generating fake news, propaganda, impersonation at scale, eroding trust.","children":[],"payload":{"tag":"li","lines":"429,430"}},{"content":"<strong>Bias and Fairness:</strong> Deployment can lead to discriminatory outcomes if biases are not mitigated. Reinforces existing inequalities.","children":[],"payload":{"tag":"li","lines":"430,431"}},{"content":"<strong>Copyright and Authorship:</strong> Issues around training data ownership and originality of generated content.","children":[],"payload":{"tag":"li","lines":"431,432"}},{"content":"<strong>Environmental Impact:</strong> Training massive models requires significant energy consumption.","children":[],"payload":{"tag":"li","lines":"432,433"}},{"content":"<strong>Accessibility &amp; Equity:</strong> The &quot;digital divide&quot; &#x2013; who benefits from and who is harmed by this technology?","children":[],"payload":{"tag":"li","lines":"433,434"}},{"content":"<strong>Over-Reliance &amp; Deskilling:</strong> Potential for atrophy of human critical thinking and writing skills.","children":[],"payload":{"tag":"li","lines":"434,435"}},{"content":"<strong>Transparency &amp; Accountability:</strong> &quot;Black box&quot; nature makes it hard to understand <em>why</em> a model produces a certain output. Who is responsible when an LLM causes harm?","children":[],"payload":{"tag":"li","lines":"435,436"}},{"content":"<strong>The Nature of Understanding:</strong> Philosophical debate &#x2013; Do LLMs truly understand, or are they sophisticated mimics (&quot;stochastic parrots&quot;)? Does it matter for their impact?","children":[],"payload":{"tag":"li","lines":"436,438"}}],"payload":{"tag":"h4","lines":"426,427"}}],"payload":{"tag":"h3","lines":"424,425"}}],"payload":{"tag":"h2","lines":"400,401"}},{"content":"The Frontier: What&apos;s Next?","children":[{"content":"Multimodality: Beyond Text","children":[{"content":"<strong>Concept:</strong> Models that can process and generate information across multiple modalities (text, images, audio, video, code).","children":[],"payload":{"tag":"li","lines":"444,445"}},{"content":"<strong>Examples:</strong> GPT-4o, Google Gemini, Meta&apos;s Llama models with vision capabilities.","children":[],"payload":{"tag":"li","lines":"445,446"}},{"content":"<strong>Capabilities:</strong> Describe images, answer questions about videos, generate images from text, follow spoken instructions, transcribe audio.","children":[],"payload":{"tag":"li","lines":"446,447"}},{"content":"<strong>Trajectory:</strong> Moving towards models that perceive and interact with the world more like humans do, integrating multiple senses.","children":[],"payload":{"tag":"li","lines":"447,448"}},{"content":"<img src=\"./imgs/44.png\" alt=\"Multimodality\">","children":[],"payload":{"tag":"li","lines":"448,450"}}],"payload":{"tag":"h3","lines":"442,443"}},{"content":"Agents &amp; Tool Use: LLMs That Act","children":[{"content":"<strong>Concept:</strong> Equipping LLMs with the ability to use external tools to overcome their limitations and interact with the world.","children":[],"payload":{"tag":"li","lines":"454,455"}},{"content":"<strong>Mechanism:</strong> The LLM acts as a &quot;reasoning engine&quot; or &quot;controller.&quot; When faced with a task it cannot do internally (e.g., current weather, complex calculation, booking a flight), it decides which tool to use, formulates the input for the tool, executes it (via API calls), and incorporates the tool&apos;s output into its response or next step.<br>\n<img src=\"./imgs/45.png\" alt=\"Agents &amp; Tool Use\"><br>\n<img src=\"./imgs/46.png\" alt=\"Agents &amp; Tool Use_2\">","children":[],"payload":{"tag":"li","lines":"455,458"}},{"content":"<strong>Examples of Tools:</strong> Web search engines, calculators, code interpreters, database query engines, calendars, e-commerce APIs.","children":[],"payload":{"tag":"li","lines":"458,459"}},{"content":"<strong>ReAct Framework:</strong> A common pattern where the agent iterates through Thought -&gt; Action -&gt; Observation cycles.","children":[],"payload":{"tag":"li","lines":"459,460"}},{"content":"<strong>Trajectory:</strong> Moving from passive text processors to active agents capable of planning and executing multi-step tasks in digital (and potentially physical) environments.","children":[],"payload":{"tag":"li","lines":"460,462"}}],"payload":{"tag":"h3","lines":"452,453"}},{"content":"Future Directions","children":[{"content":"<strong>Improved Reasoning &amp; Reliability:</strong> Reducing hallucinations, enhancing logical consistency.","children":[],"payload":{"tag":"li","lines":"466,467"}},{"content":"<strong>Personalization &amp; Memory:</strong> Models that learn user preferences and maintain long-term context.","children":[],"payload":{"tag":"li","lines":"467,468"}},{"content":"<strong>Efficiency:</strong> Smaller, faster models with comparable performance (distillation, quantization, new architectures).","children":[],"payload":{"tag":"li","lines":"468,469"}},{"content":"<strong>On-Device LLMs:</strong> Running powerful models locally on phones and laptops for privacy and offline use.","children":[],"payload":{"tag":"li","lines":"469,470"}},{"content":"<strong>Advanced Agentic Systems:</strong> More sophisticated planning, collaboration between multiple agents.","children":[],"payload":{"tag":"li","lines":"470,472"}}],"payload":{"tag":"h3","lines":"464,465"}}],"payload":{"tag":"h2","lines":"440,441"}},{"content":"Summary &amp; Key Takeaways","children":[{"content":"LLMs are powerful <strong>Transformer-based</strong> neural networks trained on vast text data, primarily via <strong>next-token prediction</strong>.","children":[],"payload":{"tag":"li","lines":"476,477"}},{"content":"Scaling (parameters, data, compute) leads to <strong>emergent abilities</strong> like few-shot learning and reasoning.","children":[],"payload":{"tag":"li","lines":"477,478"}},{"content":"<strong>Self-attention</strong> is the core mechanism enabling parallel processing and long-range context understanding.","children":[],"payload":{"tag":"li","lines":"478,479"}},{"content":"<strong>Prompt Engineering</strong> is crucial for interacting with generative models; <strong>RAG</strong> helps ground them in facts.","children":[],"payload":{"tag":"li","lines":"479,480"}},{"content":"<strong>BERT-like</strong> models excel at understanding (classification, search); <strong>GPT-like</strong> models excel at generation.","children":[],"payload":{"tag":"li","lines":"480,481"}},{"content":"The <strong>Training Pipeline</strong> (Pre-training -&gt; SFT -&gt; Alignment (RLHF/DPO)) transforms base models into helpful assistants.","children":[],"payload":{"tag":"li","lines":"481,482"}},{"content":"<strong>PEFT (LoRA/QLoRA)</strong> makes fine-tuning large models accessible for customization.","children":[],"payload":{"tag":"li","lines":"482,483"}},{"content":"LLMs have significant <strong>limitations</strong> (hallucinations, bias) and pose profound <strong>ethical and societal challenges</strong>.","children":[],"payload":{"tag":"li","lines":"483,484"}},{"content":"The future points towards <strong>multimodal models</strong> and <strong>LLM-powered agents</strong> that can interact with tools and environments.","children":[],"payload":{"tag":"li","lines":"484,485"}}],"payload":{"tag":"h2","lines":"474,475"}}],"payload":{"tag":"h1","lines":"6,7"}},{"maxWidth":700,"initialExpandLevel":2})</script>
</body>
</html>
